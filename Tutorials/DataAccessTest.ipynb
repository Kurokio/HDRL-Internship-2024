{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8356143-f305-4192-875a-0e915df681f9",
   "metadata": {},
   "source": [
    "# Data Access Check Tutorial\n",
    "This notebook shows how to use the DataAccessCheck script to test all the HAPI links in the database for data accessibility. This script was not tested on non-HAPI data access links.\n",
    "\n",
    "*Note that if you want to run for all 1632 HAPI links present in the database, expect the script to run for a LONG time. It is recommended to only do so if you are fine waiting overnight or even for an entire day or more.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bad10d-b7cd-4708-90c2-ed46afbe1762",
   "metadata": {},
   "source": [
    "## Select the amount and type of datasets you wish to test.\n",
    "\n",
    "Note that you may change the database file that is loaded in the call to create_sqlite_database. This is especially important if you created your own from scratch in the HowToUse_Advanced tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062839a-b90f-4570-8d45-f98c398b9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.DataAccessCheck import DataChecker\n",
    "from Scripts.SQLiteFun import create_sqlite_database, execution\n",
    "from contextlib import closing, redirect_stdout\n",
    "from IPython.utils.io import Tee\n",
    "\n",
    "# input abs path of database file you wish to query from\n",
    "conn = create_sqlite_database(\"/home/jovyan/HDRL-Internship-2024/SPASE_Data_20240716.db\")\n",
    "# create list to hold all dataset names acquired from db\n",
    "prodKeys = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f914ec1-e037-4a5c-95f0-1603b637e08b",
   "metadata": {},
   "source": [
    "The same functionality to sqlite statements shown in the HowToUse notebooks still applies. For instance, you can tailor the datasets you wish to test however you like, such as by mission, author, publisher, publication year, etc. This, of course, is done by adding additional WHERE arguments.\n",
    "\n",
    "A basic example query would be to select the first 10 HAPI datasets stored in the database, as shown below. Testing this amount takes ~3.7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ea345-afe0-496e-ad8b-12aa3001d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want to run on ALL 1632 datasets, remove the 'LIMIT 10' text from the query\n",
    "HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE '%/hapi' LIMIT 10\"\"\"\n",
    "prodKeys = execution(HapiStmt, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d05ca3-bf53-4490-a373-40a137de4bfb",
   "metadata": {},
   "source": [
    "Note that you can test the nth dataset(s) by offsetting where the query starts in the database. For example, if you wish to test the datasets that are in positions 60-70 in the database, you would perform the following query instead.\n",
    "\n",
    "``` python\n",
    "HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE '%/hapi' LIMIT 10 OFFSET 59\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4b40e-4b8e-4a7e-bb50-200abcc6f903",
   "metadata": {},
   "source": [
    "## Execute the script and wait for the results!\n",
    "\n",
    "The following code blocks test the datasets specified from your above query, with options to print the outputs to both the console and a text file or instead to only a text file.\n",
    "\n",
    "*If testing all datasets in the database, it is advised to only output to a text file.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ed8f6-73f3-4cf6-8c27-7c6fbb7d3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(DataChecker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb29bae-6ae6-4f5f-9426-9c4ff12e2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want output only in file\n",
    "with open(\"../DatalinkCheckOutputTest.txt\", \"w\") as file:\n",
    "    with redirect_stdout(file):\n",
    "        lines = DataChecker(prodKeys, conn)\n",
    "\n",
    "# if want both file and console\n",
    "#with closing(Tee(\"../DatalinkCheckOutputTest.txt\", \"w\", channel=\"stdout\")) as outputstream:\n",
    " #   lines = DataChecker(prodKeys, conn)\n",
    "print(\"The program is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5248f-8bbb-4a83-a4be-98df9775eebd",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "\n",
    "Now we can analyze the results, both with printouts and directly querying the database. Note that the numbers derived from each of these methods may differ if you chose to only test a portion of the HAPI links, as the results of the queries are for all 1632 links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce6dfb-e457-4b65-8206-b1e22d2848c0",
   "metadata": {},
   "source": [
    "### Console Results\n",
    "\n",
    "Before analyzing the results, the code creates another text file containing just those datasets that timed out at some or all time intervals AND failed to retrieve data. Afterwards, the code prints out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d251a-1fd5-42f7-aa4c-0f32d65b775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all datasets which take too long to a text file for further investigation\n",
    "#   can use this subset of datasets as the prodKeys argument for another script iteration\n",
    "textFile = open(\"../HAPI_TakeTooLongTest.txt\", \"w\")\n",
    "for line in lines:\n",
    "    textFile.write(line)\n",
    "    textFile.write(\"\\n\")\n",
    "textFile.close()\n",
    "\n",
    "# list that holds all datasets which failed bc of the server being overwhelmed\n",
    "Datasets = []\n",
    "\n",
    "# counts of all outcomes of results\n",
    "dataFails = 0\n",
    "tookTooLong = 0\n",
    "HAPIErrors = 0\n",
    "Unavailable = 0\n",
    "\n",
    "with open(\"../DatalinkCheckOutputTest.txt\") as file:\n",
    "    for line in file:\n",
    "        if (\"No data was found.\") in line:\n",
    "            dataFails += 1\n",
    "        elif \"Bad request - unknown dataset id\" in line:\n",
    "            Unavailable += 1\n",
    "        elif \"Problem with https://cdaweb.gsfc.nasa.gov/hapi/info?\" in line:\n",
    "            HAPIErrors += 1\n",
    "            before, sep, after = line.partition(\"Problem with https://cdaweb.gsfc.nasa.gov/hapi/info?id=\")\n",
    "            dataset, sep, after = after.partition(\".\")\n",
    "            Datasets.append(dataset)\n",
    "            \n",
    "with open(\"../HAPI_TakeTooLongTest.txt\") as file:\n",
    "    tookTooLong = len(file.readlines())\n",
    "\n",
    "dataSuccesses = len(prodKeys) - (tookTooLong + HAPIErrors + dataFails + Unavailable)\n",
    "print(\"The number of links that successfully retrieved data are \" + str(dataSuccesses))\n",
    "print(\"The number of broken links is \" + str(dataFails))\n",
    "print(\"The number of links that are not actual datasets in CDAWeb are \" + str(Unavailable))\n",
    "print(\"The number of links that encountered another HAPIError are \" + str(HAPIErrors))\n",
    "print(\"The number of links that timed out is \" + str(tookTooLong))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a734a76-774f-4943-aa93-0eb04e9b5ef7",
   "metadata": {},
   "source": [
    "### Results From Querying the Database\n",
    "\n",
    "For a more detailed explanation of the results from the script, use the following key to query the TestResults table in the database, specifically the dataAccess and Errors columns.\n",
    "\n",
    "Possible outcomes for each dataset and their corresponding message recorded in the database are as follows:\n",
    "1. Data successfully accessed --> \"Passed\" value in dataAccess\n",
    "\n",
    "> - Data was successfully accessed BUT some intervals timed out --> Also gets \"Passed after some intervals timed out\" in Errors\n",
    "\n",
    "2. No data was accessed --> \"Failed\" in dataAccess and \"HAPI data check failed after _ attempts\" in Errors\n",
    "\n",
    "> - No data was accessed but some intervals timed out --> \"Failed data check but some intervals timed out\" in Errors\n",
    "\n",
    "> - Initial data info check failed --> \"HAPI info check failed\" in Errors\n",
    "\n",
    "*Note that because I ran out of time in my internship, in order to get updated results for these queries, you must run the script for all 1632 links.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8775fd7-ddb1-4b3d-814c-aea62a03322a",
   "metadata": {},
   "source": [
    "These mirror the console output from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda4c94-b692-4de0-875b-df8ac3bb1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \"\"\" SELECT COUNT(SPASE_id) FROM TestResults WHERE dataAccess = 'Passed' \"\"\"\n",
    "passes = execution(stmt, conn)\n",
    "print(\"The number of successes are \" + str(passes[0]))\n",
    "stmt = \"\"\" SELECT COUNT(SPASE_id) FROM TestResults\n",
    "            WHERE dataAccess = 'Failed'\n",
    "            AND Errors LIKE 'HAPI data check failed after%' \"\"\"\n",
    "failures = execution(stmt, conn)\n",
    "print(\"The number of failures are \" + str(failures[0]))\n",
    "stmt = \"\"\" SELECT COUNT(SPASE_id) FROM TestResults\n",
    "            WHERE dataAccess = 'Failed'\n",
    "            AND Errors = 'HAPI info check failed' \"\"\"\n",
    "infoFails = execution(stmt, conn)\n",
    "print(\"The number of failures due to HAPIErrors are \" + str(infoFails[0]))\n",
    "stmt = \"\"\" SELECT COUNT(SPASE_id) FROM TestResults\n",
    "            WHERE dataAccess = 'Failed'\n",
    "            AND Errors = 'Failed data check but some intervals timed out' \"\"\"\n",
    "timedOut = execution(stmt, conn)\n",
    "print(\"The number of timeouts are \" + str(timedOut[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164fe67-8a9f-4744-8181-0e5f2a55ccaf",
   "metadata": {},
   "source": [
    "You can also request more info than the console provides, such as the amount of links that passed after timing out at earlier intervals. \n",
    "\n",
    "These may warrant further testing if interested in determining a minimum interval required for obtaining data for these records. This is because these records may pass the test at one of the earlier intervals, now that the HAPI metadata server is primed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be634ee-d0a6-45b8-92cb-4d598a20a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \"\"\" SELECT COUNT(SPASE_id) FROM TestResults\n",
    "            WHERE dataAccess = 'Passed'\n",
    "            AND Errors = 'Passed after some intervals timed out' \"\"\"\n",
    "passedAndTimedOut = execution(stmt, conn)\n",
    "print(\"The number of successes that may retrieve data at earlier intervals are \" + str(passedAndTimedOut[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca993-a4e5-476c-b1ce-2090c2404115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
