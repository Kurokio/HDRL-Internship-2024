{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8b4751-a921-42ad-938e-9d8b8f820c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datasets are ['AC_K1_MFI']\n",
      "Checking parameter Time in HAPI record with id AC_K1_MFI at the interval of 1s\n",
      "Data retrieval took more than 10 seconds for dataset at position 0 trying again at next interval.\n",
      "Checking parameter Time in HAPI record with id AC_K1_MFI at the interval of 10s\n",
      "Data retrieval took more than 10 seconds for dataset at position 0 trying again at next interval.\n",
      "Checking parameter Time in HAPI record with id AC_K1_MFI at the interval of 1min\n",
      "Data was successfully accessed\n"
     ]
    }
   ],
   "source": [
    "#%%capture output\n",
    "\n",
    "# once finished, try on all HAPI records and export output to file by doing the top and bottom comments\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import Scripts\n",
    "from Scripts import create_sqlite_database, execution, executionALL\n",
    "from hapiclient import hapi\n",
    "from hapiclient.util import error\n",
    "from time import sleep\n",
    "import multiprocessing\n",
    "\n",
    "# check and see if data can be retrieved from HAPI server\n",
    "def DataChecker(server, dataset, start, stop, parameters, return_dict):\n",
    "    # control loops\n",
    "    dataFound = False\n",
    "    broken = False\n",
    "    \n",
    "    try:\n",
    "        #sleep(5.0)\n",
    "        data, meta = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "    # if error(s) arise\n",
    "    #except HAPIError as err:\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        broken = True\n",
    "        #pass\n",
    "\n",
    "    # if no error arises\n",
    "    else:\n",
    "        # search for data\n",
    "        while not dataFound:\n",
    "            if len(data) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                #for entry in data:                \n",
    "                # once data is found, end loop\n",
    "                if str(data[0][0]) != \"\":\n",
    "                    dataFound = True\n",
    "                    print(\"Data was successfully accessed\")\n",
    "                    #print(\"Example data looks like \" + str(data[0][0]))\n",
    "    finally:\n",
    "        return_dict[\"dataFound\"] = dataFound\n",
    "        return_dict[\"attempts\"] += 1\n",
    "        return_dict[\"broken\"] = broken\n",
    "        return None\n",
    "\n",
    "# retrieve prodKeys associated with HAPI URLs\n",
    "\n",
    "# input abs path of database file you wish to query from\n",
    "conn = create_sqlite_database(\"/home/jovyan/HDRL-Internship-2024/SPASE_Data_20240716.db\")\n",
    "\n",
    "# fails data checks \n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 7\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 21\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 59\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 5 OFFSET 64\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 2 OFFSET 130\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 2 OFFSET 136\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 2 OFFSET 283\"\"\" takes a few tries\n",
    "\n",
    "# examples that are not actual datasets according to CDAWEB\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 3 OFFSET 120\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 14 OFFSET 233\"\"\"\n",
    "\n",
    "\n",
    "# example w multiple prodKeys\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 45\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 67\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 93\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 96\"\"\"\n",
    "\n",
    "# example where it passes data check at another interval besides 1sec\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 23\"\"\"\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 1 OFFSET 248\"\"\" incorrect\n",
    "#HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 4 OFFSET 258\"\"\" incorrect\n",
    "\n",
    "HapiStmt = \"\"\"SELECT prodKey FROM MetadataEntries WHERE url LIKE \"%/hapi\" LIMIT 10 OFFSET 285\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"spase://NASA/NumericalData/AMPTE-CCE/MEPA/PT0.1875S\n",
    "spase://NASA/NumericalData/DE2/IDM/PT0.25S\n",
    "spase://NASA/NumericalData/FAST/MAG/Fluxgate/PT7.8125MS\n",
    "spase://NASA/NumericalData/ISIS1/SFS/Ionogram/PT29S\n",
    "spase://NASA/NumericalData/MESSENGER/MAG/PT0.05S\"\"\"\n",
    "\n",
    "prodKeys = []\n",
    "prodKeys = execution(HapiStmt, conn)\n",
    "print(\"The datasets are \" + str(prodKeys))\n",
    "\n",
    "\n",
    "server = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "\n",
    "# iterate thru prodKeys to assign as dataset\n",
    "for prodKey in prodKeys:\n",
    "    # check if multiple prodKeys for same URL (mult keys in one string)\n",
    "    if \", \" in prodKey:\n",
    "        print(\"This HAPI URL has multiple product keys.\")\n",
    "        index = prodKeys.index(prodKey)\n",
    "        prodKey = prodKey.replace(\"\\'\", \"\")\n",
    "        # keep separating them until each prodKey is in own string\n",
    "        # while \", \" in prodKey:\n",
    "        before, sep, after = prodKey.partition(\", \")\n",
    "        prodKeys[index] = before # remove this line if need to check all keys\n",
    "        #prodKeys[index] = after\n",
    "        #prodKeys.insert(index, before)\n",
    "        prodKey = prodKeys[index]\n",
    "    dataset = str(prodKey)\n",
    "    \n",
    "    # control loops\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    # count of attempts to get data\n",
    "    return_dict[\"attempts\"] = 0\n",
    "    return_dict[\"dataFound\"] = False\n",
    "    return_dict[\"broken\"] = False\n",
    "    #dataFound = False\n",
    "    #broken = False\n",
    "    \n",
    "    # list that holds all parameters for a given server\n",
    "    paramNames =  []\n",
    "\n",
    "    # retrieve all parameters and the start date from the server\n",
    "    sleep(5.0)\n",
    "    meta = hapi(server,dataset)\n",
    "    # get parameters\n",
    "    for k, v in meta.items():\n",
    "        if k == \"parameters\":\n",
    "            for params in v:\n",
    "                for key, value in params.items():\n",
    "                    if key == \"name\":\n",
    "                        paramNames.append(value)\n",
    "        # get start date\n",
    "        elif k == \"startDate\":\n",
    "            start = v\n",
    "\n",
    "    #print(paramNames)\n",
    "\n",
    "    # dictionary that holds datetime obj for each interval\n",
    "    intervals = {}\n",
    "    intervals[\"1s\"] = \"\"\n",
    "    intervals[\"10s\"] = \"\"\n",
    "    intervals[\"1min\"] = \"\"\n",
    "    intervals[\"10min\"] = \"\"\n",
    "    intervals[\"1hr\"] = \"\"\n",
    "    intervals[\"1d\"] = \"\"\n",
    "    intervals[\"3d\"] = \"\"\n",
    "    intervals[\"1w\"] = \"\"\n",
    "    intervals[\"1mon\"] = \"\"\n",
    "    \n",
    "    # create incremental intervals to test for data check\n",
    "    date, sep, time = start.partition(\"T\")\n",
    "    time = time.replace(\"Z\", \"\")\n",
    "    dt_string = date + \" \" + time\n",
    "    dt_obj = datetime.strptime(dt_string, \"%Y-%m-%d %H:%M:%S\")\n",
    "    # 1 second\n",
    "    intervals[\"1s\"] = dt_obj + timedelta(seconds=1)\n",
    "    # 10 seconds\n",
    "    intervals[\"10s\"] = dt_obj + timedelta(seconds=10)\n",
    "    # 1 minute\n",
    "    intervals[\"1min\"] = dt_obj + timedelta(minutes=1)\n",
    "    # 10 minutes\n",
    "    intervals[\"10min\"] = dt_obj + timedelta(minutes=10)\n",
    "    # hour\n",
    "    intervals[\"1hr\"] = dt_obj + timedelta(hours=1)\n",
    "    # day\n",
    "    intervals[\"1d\"] = dt_obj + timedelta(days=1)\n",
    "    # 3 days\n",
    "    intervals[\"3d\"] = dt_obj + timedelta(days=3)\n",
    "    # week\n",
    "    intervals[\"1w\"] = dt_obj + timedelta(weeks=1)\n",
    "    # month\n",
    "    intervals[\"1mon\"] = dt_obj + timedelta(weeks=4,days=2)\n",
    "\n",
    "    # to iterate thru all parameters in a server, use the for loop below to enclose the code below\n",
    "    # for parameters in paramNames[1:]:\n",
    "    \n",
    "    # UNFINISHED: have data check occur in increasingly larger start/stop intervals until data is returned\n",
    "    #              and only check for one parameter (Time is fine)\n",
    "    parameter = paramNames[0]\n",
    "    for k, v in intervals.items():\n",
    "        if (not return_dict[\"dataFound\"]) and (not return_dict[\"broken\"]):\n",
    "            stop = str(v)\n",
    "            stop = stop.replace(\" \", \"T\") + \"Z\"\n",
    "            print(\"Checking parameter \" + str(parameter) + \" in HAPI record with id \" + dataset +\n",
    "                  \" at the interval of \" + str(k))\n",
    "            \"\"\"dataFound, attempts, broken = DataChecker(server, dataset, start, stop,\n",
    "                                              parameter, attempts)\"\"\"\n",
    "            p = multiprocessing.Process(target=DataChecker, args=(server, dataset, start, stop,\n",
    "                                              parameter, return_dict))\n",
    "            sleep(5.0)\n",
    "            p.start()\n",
    "            p.join(10)\n",
    "            # add export to text file that contains the prodKey/dataset that took too long for a retry later\n",
    "            if p.is_alive():\n",
    "                print(f\"Data retrieval took more than 10 seconds for dataset at position {prodKeys.index(prodKey)}\" +\n",
    "                      \" trying again at next interval.\")\n",
    "                p.terminate()\n",
    "                return_dict[\"attempts\"] += 1\n",
    "    # if all intervals fail or link is broken -> no data\n",
    "    if not return_dict[\"dataFound\"]:\n",
    "    # inputs \"HAPI info check passed after 1 attempt. HAPI data check failed after x attempts.\"\n",
    "    #     into \"Error\" column in TestResults associated with that HAPI URL\n",
    "        print(\"No data was found\")\n",
    "\n",
    "#with open(\"../DatalinkCheckOutput.txt\", \"w\") as file:\n",
    " #   file.write(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155678d0-d2d5-48de-9c5a-2403cd725c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The program is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f21b7de-c3c1-4cf6-8c8c-2c63856cf5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call .py file directly from notebook\n",
    "#%run ./HAPICheck.py > ../DatalinkCheckOutput.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039c039-f965-4d57-b3d4-1af271ab73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "        errMessage = \"HAPI info check passed after 1 attempt. HAPI data check\"\n",
    "        errMessage += f\" failed after {return_dict['attempts']} attempt(s).\"\n",
    "        HAPIErrorStmt = f\"\"\" UPDATE TestResults\n",
    "                                SET Errors = '{errMessage}'\n",
    "                                FROM (SELECT SPASE_id, prodKey FROM TestResults\n",
    "                                        INNER JOIN MetadataEntries USING (SPASE_id))\n",
    "                                WHERE prodKey = '{dataset}' \"\"\"\n",
    "        Record_id = execution(f\"\"\" SELECT rowNum \n",
    "                                FROM (SELECT TestResults.rowNum, SPASE_id, prodKey FROM TestResults \n",
    "                                    INNER JOIN MetadataEntries USING (SPASE_id))\n",
    "                                WHERE prodKey = '{dataset}';\"\"\", conn)\n",
    "        executionALL(HAPIErrorStmt, conn)\n",
    "        print(f\"Sent error message to a TestResults entry with the row number {Record_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793fb1b-bf0a-4ac9-9c9f-77c4ae50bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hapiclient.util import HAPIError\n",
    "dir(HAPIError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3af2a2dd-a8e9-4e32-8bc6-120eb6bccb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodKeys.index(\"I1_AV_ULA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be509b-9b63-4fa0-b7bc-57be93b09bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
