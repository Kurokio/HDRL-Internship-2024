{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb448f-0864-43cb-9690-e281a5378c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from .py files\n",
    "import pprint, sqlite3\n",
    "from SPASE_Scraper_Script import SPASE_Scraper\n",
    "from PathGrabber import getPaths\n",
    "\n",
    "# list that holds paths returned by PathGrabber\n",
    "SPASE_paths = []\n",
    "\n",
    "# print Flag (True prints, False does not)\n",
    "printFlag = False\n",
    "\n",
    "# get user input and extract all SPASE records\n",
    "print(\"Enter root folder you want to search\")\n",
    "folder = input()\n",
    "print(\"You entered \" + folder)\n",
    "SPASE_paths = getPaths(folder, SPASE_paths)\n",
    "if printFlag:\n",
    "    print(\"The number of records is \"+ str(len(SPASE_paths)))\n",
    "    print(\"The SPASE records found are:\")\n",
    "    print(SPASE_paths)\n",
    "print(\"===========================================================================================================\")\n",
    "\n",
    "# lists that hold URLs to be exported and SPASE records already checked\n",
    "lines = []\n",
    "searched = []\n",
    "\n",
    "# iterate through all SPASE records returned by PathGrabber\n",
    "for record in SPASE_paths:\n",
    "    # scrape metadata for each record\n",
    "    if record not in searched:\n",
    "        (RID, RIDField, author, authorField, pub, pubField, pubDate, pubDateField, dataset, datasetField, \n",
    "         desc, descField, PI, PIField, AccessRights, licenseField, datalinkField) = SPASE_Scraper(record)\n",
    "        searched.append(record)\n",
    "        pubYear = pubDate[0:4]\n",
    "        author = \", \".join(author)\n",
    "        if printFlag:\n",
    "            print(\"The ResourceID is \" + RID + \" which was obtained from \" + RIDField)\n",
    "            print(\"The author(s) are \" + author + \" which was obtained from \" + authorField)\n",
    "            print(\"The publication year is \" + pubYear + \" which was obtained from \" + pubDateField)\n",
    "            print(\"The publisher is \" + pub + \" which was obtained from \" + pubField)\n",
    "            print(\"The dataset is \" + dataset + \" which was obtained from \" + datasetField)\n",
    "            print(\"The description is \" + desc + \" which was obtained from \" + descField)\n",
    "            print(\"The persistent identifier is \" + PI + \" which was obtained from \" + PIField)\n",
    "            print(\"The URLs with their associated product keys obtained from \" + datalinkField + \"\"\" and their \n",
    "                  license(s) obtained from \"\"\" + licenseField + \" are: \")\n",
    "            pprint.pprint(AccessRights)\n",
    "\n",
    "        datalink = \"\"\n",
    "        license = \"\"\n",
    "        desired = False\n",
    "\n",
    "        # separate license from the datalink and product keys from AccessRights to store in db\n",
    "        for k, v in AccessRights.items():\n",
    "            if not v:\n",
    "                continue\n",
    "            else:\n",
    "                license = k\n",
    "                # check if any urls are for consideration\n",
    "                for link in v.keys():\n",
    "                    if (\"nasa.gov\" or \"virtualsolar.org\") in link:\n",
    "                        desired = True\n",
    "                #datalink = str(v)\n",
    "                for key, val in v.items():\n",
    "                    # allow desired URLs to be added to database\n",
    "                    if (\"nasa.gov\" or \"virtualsolar.org\") in key:\n",
    "                        datalink += str(key) + \": \" + str(val) + \" \\n\"\n",
    "                    else:\n",
    "                        # if no desired URLs present, add URLs to text file list\n",
    "                        if not desired:\n",
    "                            lines.append(RID + \", \" + str(key))\n",
    "                if printFlag:\n",
    "                    print(k + \" was assigned to license\")\n",
    "                    #for key, val in v.items():\n",
    "                     #   datalink = key\n",
    "                      #  prodKey = val\n",
    "                    print(datalink + \" was assigned to datalink\")\n",
    "\n",
    "\n",
    "        # add table to existing database\n",
    "\n",
    "        def create_tables():\n",
    "            sql_statements = [ \n",
    "                \"\"\"CREATE TABLE IF NOT EXISTS SPASE_Metadata (\n",
    "                        id INTEGER PRIMARY KEY, \n",
    "                        SPASE_id TEXT NOT NULL UNIQUE, \n",
    "                        author TEXT,\n",
    "                        author_source TEXT,\n",
    "                        publisher TEXT,\n",
    "                        publisher_source TEXT,\n",
    "                        publication_yr TEXT,\n",
    "                        publication_yr_source TEXT,\n",
    "                        dataset TEXT,\n",
    "                        dataset_source TEXT,\n",
    "                        license TEXT,\n",
    "                        license_source TEXT,\n",
    "                        datalink TEXT,\n",
    "                        datalink_source TEXT,\n",
    "                        description TEXT,\n",
    "                        description_source TEXT,\n",
    "                        PI TEXT,\n",
    "                        PI_source TEXT\n",
    "                );\"\"\"]\n",
    "\n",
    "            # create a database connection\n",
    "            try:\n",
    "                with sqlite3.connect('SPASE_Data.db') as conn:\n",
    "                    cursor = conn.cursor()\n",
    "                    for statement in sql_statements:\n",
    "                        cursor.execute(statement)\n",
    "\n",
    "                    conn.commit()\n",
    "            except sqlite3.Error as e:\n",
    "                print(e)\n",
    "\n",
    "        create_tables()\n",
    "\n",
    "        # insert metadata entries into table\n",
    "\n",
    "        def add_SPASE(conn, entry):\n",
    "            sql = '''INSERT INTO SPASE_Metadata(SPASE_id,author,author_source,publisher,publisher_source,\n",
    "                    publication_yr,publication_yr_source,dataset,dataset_source,license,license_source,\n",
    "                    datalink,datalink_source,description,description_source,PI,PI_source)\n",
    "                    VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?) '''\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(sql, entry)\n",
    "            conn.commit()\n",
    "            return cur.lastrowid\n",
    "\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect('SPASE_Data.db') as conn:\n",
    "                # add a new SPASE Record\n",
    "                SPASE_Record = (RID, author, authorField, pub, pubField, pubYear, pubDateField, \n",
    "                                dataset, datasetField, license, licenseField, datalink, datalinkField,\n",
    "                                desc, descField, PI, PIField)\n",
    "                Record_id = add_SPASE(conn, SPASE_Record)\n",
    "                print(f'Created a SPASE Record with the id {Record_id}')\n",
    "\n",
    "        except sqlite3.Error as e:\n",
    "            print(e)\n",
    "\n",
    "        print(\"===========================================================================================================\")\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "# add SPASE records without desired links to a text file\n",
    "textFile = open(\"../NoLinkRecords.txt\", \"a\")\n",
    "repeat = []\n",
    "for line in lines:\n",
    "    rid, url = line.split(\",\")\n",
    "    if url not in repeat:\n",
    "        textFile.write(line)\n",
    "        textFile.write(\"\\n\")\n",
    "        repeat.append(url)\n",
    "textFile.close()\n",
    "\n",
    "# call .py file directly from notebook\n",
    "#%run ./SPASE_test.py {path} in notebook\n",
    "#import sys\n",
    "#args = sys.argv\n",
    "#path = args[1] in source file\n",
    "\n",
    "# test path : Big = \"/home/jovyan/NASA/NumericalData/DE2\" or Small = \"/home/jovyan/NASA/NumericalData/ACE/EPAM/RATES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db45fe2-8522-40af-8d6e-79513c3b4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = open(\"../NoLinkRecords.txt\", \"w\")\n",
    "textFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86ae661-0102-482c-a9ad-6b31e39c53fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Takes path of a .xml SPASE record file and returns a tuple of values of varying types which hold all \\n    desired metadata and the fields they came from. This will collect the desired metadata following the \\n    priority rules determined by SPASE record experts. If any desired metadata is not found, the default \\n    value assigned is an empty string.\\n    \\n    :param path: A string of the absolute/relative path of the SPASE record to be scraped.\\n    :type path: String\\n    :return: A tuple containing the metadata desired and where they were obtained.\\n    :rtype: tuple\\n    '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SPASE_Scraper_Script import SPASE_Scraper\n",
    "\n",
    "SPASE_Scraper.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cfc47-63fd-46b1-a84f-5fc4d9c7bd26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
